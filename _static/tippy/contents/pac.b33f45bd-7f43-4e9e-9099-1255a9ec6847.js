selector_to_html = {"a[href=\"#equation-testoneh\"]": "<div class=\"math notranslate nohighlight\" id=\"equation-testoneh\">\n\\[\\proba\\left[|L_\\mathcal D(h_S)-L_T(h_S)|\\geq\\epsilon\\right]\\leq 2e^{-{2|T|\\epsilon^2}}\\]</div>", "a[href=\"#equation-geneq\"]": "<div class=\"math notranslate nohighlight\" id=\"equation-geneq\">\n\\[L_{\\mathcal D}(h_S)=\\underbrace{\\left(L_{\\mathcal D}(h_S)-L_{T}(h_S)\\right)}_{\\text{small}}+\n\\underbrace{\\left(L_{T}(h_S)-L_{S}(h_S)\\right)}_{\\text{generalisation gap}}+\n\\underbrace{L_{S}(h_S)}_{\\text{training error}}\\]</div>", "a[href=\"#pac-learning\"]": "<h1 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">2. </span>PAC learning<a class=\"headerlink\" href=\"#pac-learning\" title=\"Link to this heading\">#</a></h1><p>Let\u2019s imagine we urgently need a good classifier that distinguishes cat pictures from dog pictures.<label class=\"margin-toggle\" for=\"sidenote-role-1\"><span id=\"id1\">\n<sup>1</sup></span>\n</label><input class=\"margin-toggle\" id=\"sidenote-role-1\" name=\"sidenote-role-1\" type=\"checkbox\"/><span class=\"sidenote\"><sup>1</sup>Much of the material is based on <em>Understanding Machine Learning</em> by Shai Shalev-Shwartz and Shai Ben-David</span>\nHow do we go about this? We perhaps decide that a neural network will be suitable and we\nprepare a training set: we collect cat and dog pictures and we label each picture as either\na cat picture or a dog picture. Once we have done that we run an optimisation algorithm\nto adapt the weights of the neural network so that the training error, the\nmisclassification rate on the training set, is as small as possible. (We will discuss\nsuch optimisation algorithms in a later chapter.) What concerns us here is:\nWhy can we expect a neural network with small training error to perform well on new data?</p><p>Recall: We do not care about the training set. We already know which picture in the training\nset is a cat and which is a dog. What we care about is performance on new data, ie,\nwe strive for a small generalisation error.\nDoes a small training error <em>guarantee</em> a small generalisation error?\nIn short: No.</p>", "a[href=\"#testerrvarfig\"]": "<figure class=\"align-default\" id=\"testerrvarfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/testerr_var.png\"><img alt=\"../_images/testerr_var.png\" src=\"../_images/testerr_var.png\" style=\"width: 8cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.2 </span><span class=\"caption-text\">Test errors of a decision tree on the MNIST task. Training set size was 20000 samples.\nThe remaining data was partitioned into 100 test sets of size 500 each. The histogram shows the\ndistribution of errors on these tests sets.</span><a class=\"headerlink\" href=\"#testerrvarfig\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#empirical-risk-minimisation\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">2.1. </span>Empirical risk minimisation<a class=\"headerlink\" href=\"#empirical-risk-minimisation\" title=\"Link to this heading\">#</a></h2><p>How do we train a classifier?\nGiven a domain set <span class=\"math notranslate nohighlight\">\\(\\mathcal X\\)</span> and a set of classes <span class=\"math notranslate nohighlight\">\\(\\mathcal Y\\)</span>, and\na (hidden) distribution <span class=\"math notranslate nohighlight\">\\(\\mathcal D\\)</span> on <span class=\"math notranslate nohighlight\">\\(\\mathcal X\\times\\mathcal Y\\)</span>, we\ndraw a training set <span class=\"math notranslate nohighlight\">\\(S\\)</span> of size <span class=\"math notranslate nohighlight\">\\(m\\)</span> from the distribution <span class=\"math notranslate nohighlight\">\\(\\mathcal D\\)</span>.\nWe write <span class=\"math notranslate nohighlight\">\\(S\\sim\\mathcal D^m\\)</span> to denote that we draw <span class=\"math notranslate nohighlight\">\\(m\\)</span> samples from <span class=\"math notranslate nohighlight\">\\(S\\)</span>\nindepedently of each other.  Observe that it might happen that we draw a given point twice or even more\noften.\nHow now should we choose a classifier <span class=\"math notranslate nohighlight\">\\(h:\\mathcal X\\to\\mathcal Y\\)</span>? It should have low training error.\nOften, in this context, the training error is also called \\defi{empirical risk}:</p>", "a[href=\"#overfitting-and-underfitting\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">2.3. </span>Overfitting and underfitting<a class=\"headerlink\" href=\"#overfitting-and-underfitting\" title=\"Link to this heading\">#</a></h2><p>By <a class=\"reference internal\" href=\"#testerrthm\">Theorem 2.2</a>, the first part can be seen to be reasonably small, and the last part is\nsimply the training error, aka, the empirical risk. The difference between test and training error\nis also called the \\defi{generalisation gap}. A large generalisation gap\nmeans that the classifier learns the training set and not the underlying distribution <span class=\"math notranslate nohighlight\">\\(\\mathcal D\\)</span>.\nIn other words, the classifier is <em>overfitting</em>. Often this is the case because the classifier\n(or rather the class <span class=\"math notranslate nohighlight\">\\(\\mathcal H\\)</span>) has too many degrees of freedom.\nIf the training error is large then\nthe classifier is not flexible enough to accomodate the training set \u2014 it is said to <em>underfit</em>; see <a class=\"reference internal\" href=\"#underfitfig\"><span class=\"std std-numref\">Fig. 2.4</span></a>.</p>", "a[href=\"#testerrthm\"]": "<div class=\"proof theorem admonition\" id=\"testerrthm\">\n<p class=\"admonition-title\"><span class=\"caption-number\">Theorem 2.2 </span></p>\n<section class=\"theorem-content\" id=\"proof-content\">\n<p>Let <span class=\"math notranslate nohighlight\">\\(h\\)</span> be some classifier, let <span class=\"math notranslate nohighlight\">\\(\\delta&gt;0\\)</span>, and let <span class=\"math notranslate nohighlight\">\\(T\\)</span> be a test set. Then\nwith probability at least <span class=\"math notranslate nohighlight\">\\(1-\\delta\\)</span> (over the choice of <span class=\"math notranslate nohighlight\">\\(T\\)</span>):</p>\n<div class=\"math notranslate nohighlight\">\n\\[\nL_{\\mathcal D}(h)\\leq L_T(h)+\\sqrt{\\frac{\\ln(2/\\delta)}{2|T|}}\n\\]</div>\n</section>\n</div>", "a[href=\"#shatterfig\"]": "<figure class=\"align-default\" id=\"shatterfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/axisrect.png\"><img alt=\"../_images/axisrect.png\" src=\"../_images/axisrect.png\" style=\"width: 10cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.6 </span><span class=\"caption-text\">Four points in the plane shattered by axis-parallel rectangles.</span><a class=\"headerlink\" href=\"#shatterfig\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#underfitfig\"]": "<figure class=\"align-default\" id=\"underfitfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/underfit.png\"><img alt=\"../_images/underfit.png\" src=\"../_images/underfit.png\" style=\"width: 12cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.4 </span><span class=\"caption-text\">The linear predictor on the left underfits the training set. The quadratic predictor on the\nright fits the training set perfectly.</span><a class=\"headerlink\" href=\"#underfitfig\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#equation-ermparadigm\"]": "<div class=\"math notranslate nohighlight\" id=\"equation-ermparadigm\">\n\\[h_S=\\argmin_{h\\in\\mathcal H} L_S(h)\\]</div>", "a[href=\"#decoverfig\"]": "<figure class=\"align-default\" id=\"decoverfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/dec_overfit.png\"><img alt=\"../_images/dec_overfit.png\" src=\"../_images/dec_overfit.png\" style=\"width: 15cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.1 </span><span class=\"caption-text\">Datapoints in top half are class +$ with 90% probability,\nin lower half they are class -1 with 90% probability. Shown are\nfour trained predictors, each time with training set and decision boundary.\nTop left: Neural network with one hidden layer of 10 neurons. Top right: Neural network\nwith two hidden layers of 100 neurons each. Lower left: Decision tree of depth 1 (ie, a single decision rule).\nLower right: Decision tree grown to full height (with zero training error).\nThe simpler predictors, in the left column, show better generalisation than the more\npowerful ones in the right column.</span><a class=\"headerlink\" href=\"#decoverfig\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#test-error-and-generalisation-error\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">2.2. </span>Test error and generalisation error<a class=\"headerlink\" href=\"#test-error-and-generalisation-error\" title=\"Link to this heading\">#</a></h2><p>We have introduced the test set as a stand-in for new data. Let\u2019s see\nwhat the test error can tell us about the generalisation error.</p><p>We need a <em>measure concentration</em> inequality, an inequality that\nasserts that the mean of certain random variables is, with high probability,\nvery close to the expected value \u2013 provided a number of mild conditions are satisfied.<label class=\"margin-toggle marginnote-label\" for=\"marginnote-role-2\"></label><input class=\"margin-toggle\" id=\"marginnote-role-2\" name=\"marginnote-role-2\" type=\"checkbox\"/><span class=\"marginnote\"> <a class=\"reference external\" href=\"https://colab.research.google.com/github/henningbruhn/math_of_ml_course/blob/main/pac_learning/concentration.ipynb\"><svg aria-hidden=\"true\" class=\"sd-material-icon sd-material-icon-terminal\" height=\"2.0em\" version=\"4.0.0.63c5cb3\" viewbox=\"0 0 24 24\" width=\"2.0em\"><g><rect fill=\"none\" height=\"24\" width=\"24\"></rect></g><g><path d=\"M20,4H4C2.89,4,2,4.9,2,6v12c0,1.1,0.89,2,2,2h16c1.1,0,2-0.9,2-2V6C22,4.9,21.11,4,20,4z M20,18H4V8h16V18z M18,17h-6v-2 h6V17z M7.5,17l-1.41-1.41L8.67,13l-2.59-2.59L7.5,9l4,4L7.5,17z\"></path></g></svg>concentration</a></span></p>", "a[href=\"#equation-ggengap\"]": "<div class=\"math notranslate nohighlight\" id=\"equation-ggengap\">\n\\[L_{\\mathcal D}(h_S)-L_{S}(h_S),\\]</div>", "a[href=\"#nolinfig\"]": "<figure class=\"align-default\" id=\"nolinfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/fourpoints.png\"><img alt=\"../_images/fourpoints.png\" src=\"../_images/fourpoints.png\" style=\"height: 2cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.5 </span><span class=\"caption-text\">No linear classifier can fit the four points perfectly.</span><a class=\"headerlink\" href=\"#nolinfig\" title=\"Link to this image\">#</a></p>\n</figcaption>\n</figure>", "a[href=\"#memalgo\"]": "<div class=\"math notranslate nohighlight\" id=\"memalgo\">\n\\[\\begin{split}\\text{Mem}(x)=\n\\begin{cases}\ny &amp;\\text{if }(x,y)\\in S\\\\\n1 &amp;\\text{else}\n\\end{cases}\\end{split}\\]</div>", "a[href=\"#vc-dimension\"]": "<h2 class=\"tippy-header\" style=\"margin-top: 0;\"><span class=\"section-number\">2.4. </span>VC-dimension<a class=\"headerlink\" href=\"#vc-dimension\" title=\"Link to this heading\">#</a></h2><p>Quadratic classifiers seem more powerful, more expressive than linear classifiers.\nHow can we state this formally? How can we measure the, well, <em>expressiveness</em>\nof a set of classifiers?</p><p>Arguably, a set of classifiers is more powerful than another if it can\nfit larger complicated training sets perfectly. Obviously, any classifier\ncan fit large training sets if the classes are just right: indeed,\nlinear classifiers classify abritrarily large training sets correctly,\nprovided the sets are separable. With another setting of classes, however,\na linear classifier will already fail to fit four points perfectly; see <a class=\"reference internal\" href=\"#nolinfig\"><span class=\"std std-numref\">Fig. 2.5</span></a>.\nA quadratic classifier, in contrast, will still be able to fit most\nconfigurations of four points \u2013 whatever the classes.</p>", "a[href=\"#gengapfig\"]": "<figure class=\"align-default\" id=\"gengapfig\">\n<a class=\"reference internal image-reference\" href=\"../_images/gengap.png\"><img alt=\"../_images/gengap.png\" src=\"../_images/gengap.png\" style=\"height: 8cm;\"/>\n</a>\n<figcaption>\n<p><span class=\"caption-number\">Fig. 2.3 </span><span class=\"caption-text\">More training data, smaller generalisation gap. MNIST data set, decision tree\nwith max depth fixed to 10.```</span><a class=\"headerlink\" href=\"#gengapfig\" title=\"Link to this image\">#</a></p>\n<div class=\"legend\">\n<p>Given a training set <span class=\"math notranslate nohighlight\">\\(S\\)</span> and test set <span class=\"math notranslate nohighlight\">\\(T\\)</span> we can decompose the true risk of <span class=\"math notranslate nohighlight\">\\(h_S\\)</span> as follows:</p>\n<div class=\"math notranslate nohighlight\" id=\"equation-geneq\">\n<span class=\"eqno\">(2.5)<a class=\"headerlink\" href=\"#equation-geneq\" title=\"Link to this equation\">#</a></span>\\[L_{\\mathcal D}(h_S)=\\underbrace{\\left(L_{\\mathcal D}(h_S)-L_{T}(h_S)\\right)}_{\\text{small}}+\n\\underbrace{\\left(L_{T}(h_S)-L_{S}(h_S)\\right)}_{\\text{generalisation gap}}+\n\\underbrace{L_{S}(h_S)}_{\\text{training error}}\\]</div>\n</div>\n</figcaption>\n</figure>", "a[href=\"#equation-oneh\"]": "<div class=\"math notranslate nohighlight\" id=\"equation-oneh\">\n\\[\\proba\\left[|L_\\mathcal D(h)-L_S(h)|\\geq\\epsilon\\right]\\leq 2e^{-{2m\\epsilon^2}}\\]</div>"}
skip_classes = ["headerlink", "sd-stretched-link"]

window.onload = function () {
    for (const [select, tip_html] of Object.entries(selector_to_html)) {
        const links = document.querySelectorAll(` ${select}`);
        for (const link of links) {
            if (skip_classes.some(c => link.classList.contains(c))) {
                continue;
            }

            tippy(link, {
                content: tip_html,
                allowHTML: true,
                arrow: true,
                placement: 'auto-start', maxWidth: 500, interactive: false,
                onShow(instance) {MathJax.typesetPromise([instance.popper]).then(() => {});},
            });
        };
    };
    console.log("tippy tips loaded!");
};
