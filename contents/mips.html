<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Maximum inner product search &#8212; firsttest  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=686e5160" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="firsttest documentation" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="maximum-inner-product-search">
<h1>Maximum inner product search<a class="headerlink" href="#maximum-inner-product-search" title="Link to this heading">¶</a></h1>
<p>Vector databases are becoming more and more important.
What’s a vector database? A system to store a large number of vectors
<span class="math notranslate nohighlight">\(x^{(1)},\ldots, x^{(n)}\in\mathbb R^d\)</span>
in such a way that a (approximate) nearest neighbour search can be performed efficiently.
A recommender system, for instance, might
store the preferences of the users encoded as vectors; for a new user the five most similar
known users could be computed in order to recommend the products or services they prefered.
Another application comes from word or document embeddings: A number of vector representation
of documents are stored in the database; a user may then formulate a query (“which Tom Stoppard play
features Hamlet as a side character?”) that is transformed into a vector; the documents with
most similar vector representation are then returned.</p>
<p>What <em>most similar</em> means will differ from application to application. Often it may
simply mean: the largest scalar product. That is, given a query
<span class="math notranslate nohighlight">\(q\in\mathbb R^d\)</span> we look for the
<span class="math notranslate nohighlight">\(x^{(i)}\)</span>
with largest
<span class="math notranslate nohighlight">\(q^\intercal x^{(i)}\)</span>.
In that case, the problem is known as <em>maximum inner product search</em> (or MIPS).</p>
<p>At first, the computational problem may appear to have an easy solution – after all, scalar
products can be computed very efficiently. With <span class="math notranslate nohighlight">\(n\)</span> vectors in the database, each with length <span class="math notranslate nohighlight">\(d\)</span>,
checking every scalar product amounts to a running time of <span class="math notranslate nohighlight">\(O(nd)\)</span>. The number of vectors, <span class="math notranslate nohighlight">\(n\)</span>,
however, will usually be extremely large, perhaps even in the billions, and the dimension <span class="math notranslate nohighlight">\(d\)</span> may
have three or four digits. Moreover, queries typically need to be answered very quickly. A recommender system,
for example, could easily need to address hundreds or thousands of queries every second.
As a result, a running time of <span class="math notranslate nohighlight">\(O(nd)\)</span> may be too slow.
How can this be sped up?</p>
<section id="vector-quantisation">
<h2>Vector quantisation<a class="headerlink" href="#vector-quantisation" title="Link to this heading">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(x^{(1)},\ldots x^{(n)}\in\mathbb R^d\)</span> be the vectors  that make up the database,
let <span class="math notranslate nohighlight">\(k,m&gt;0\)</span> be integers, and let <span class="math notranslate nohighlight">\(\ell=\tfrac{d}{m}\)</span>, which we assume to be an integer. <a class="footnote-reference brackets" href="#fquant" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
<p>We split each vector <span class="math notranslate nohighlight">\(x\in\mathbb R^d\)</span> into <span class="math notranslate nohighlight">\(m\)</span> vectors each of length <span class="math notranslate nohighlight">\(\ell\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x=\begin{pmatrix}x_1\\x_2\\\vdots\\x_m\end{pmatrix}, \text{ with }x_j\in\mathbb R^\ell\text{ for }j=1,\ldots, m\end{split}\]</div>
<p>(In practice, this partition of <span class="math notranslate nohighlight">\(\mathbb R^d\)</span> into subspaces is achieved by random sampling of the entry dimensions.)</p>
<p>Then, for <span class="math notranslate nohighlight">\(j=1,\ldots,m\)</span> we compute representative vectors <span class="math notranslate nohighlight">\(c_{1j},\ldots,c_{kj}\in\mathbb R^\ell\)</span>.
These are used to replace the database vectors by simpler vectors: For each <span class="math notranslate nohighlight">\(i=1,\ldots, n\)</span> and <span class="math notranslate nohighlight">\(j=1,\ldots, m\)</span>
we find a suitable <span class="math notranslate nohighlight">\(\hat x^{(i)}_j\in\{c_{j1},\ldots,c_{jk}\}\)</span>. That is, we basically replace <span class="math notranslate nohighlight">\(x^{(i)}_j\)</span> by one of <span class="math notranslate nohighlight">\(\{c_{j1},\ldots,c_{jk}\}\)</span>.
In this way <span class="math notranslate nohighlight">\(x^{(i)}\)</span> is replaced by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat x^{(i)}=\begin{pmatrix}\hat x^{(i)}_1\\\vdots\\\hat x^{(i)}_m\end{pmatrix}\end{split}\]</div>
<p>For a query <span class="math notranslate nohighlight">\(q\in\mathbb R^d\)</span> we then approximate <span class="math notranslate nohighlight">\(q^\intercal x^{(i)}\approx q^\intercal\hat x^{(i)}\)</span>.</p>
<p>Before we look at <span class="math notranslate nohighlight">\(q\hat x^{(i)}\)</span> let me point out that replacing each <span class="math notranslate nohighlight">\(x^{(i)}\)</span> by <span class="math notranslate nohighlight">\(\hat x^{(i)}\)</span>
already results in a welcome compression of the data. Indeed, we only need to store all <span class="math notranslate nohighlight">\(c_{js}\)</span>, <span class="math notranslate nohighlight">\(j=1,\ldots, m\)</span>, <span class="math notranslate nohighlight">\(s=1,\ldots, k\)</span>
and, instead of <span class="math notranslate nohighlight">\(x^{(i)}\)</span> we store a vector <span class="math notranslate nohighlight">\(\hat z^{(i)}\in\{1,\ldots,k\}^m\)</span> with <span class="math notranslate nohighlight">\(\hat z^{(i)}_j=s\)</span> if and only if <span class="math notranslate nohighlight">\(\hat x^{(i)}_j=c_{js}\)</span>.</p>
<p>What is the computational complexity to compute <span class="math notranslate nohighlight">\(q^\intercal\hat x^{(i)}\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>?
We write</p>
<div class="math notranslate nohighlight">
\[q^\intercal\hat x^{(i)} = \sum_{j=1}^mq^\intercal_j\hat x^{(i)}_j\]</div>
<p>Note that <span class="math notranslate nohighlight">\(\hat x^{(i)}_j\)</span> is one of <span class="math notranslate nohighlight">\(c_{j1},\ldots, c_{jk}\)</span>. We first compute all scalar products <span class="math notranslate nohighlight">\(q^\intercal_jc_{js}\)</span> and
put them in a look-up table. Computing the scalar product takes <span class="math notranslate nohighlight">\(O(mk\ell)\)</span> time as <span class="math notranslate nohighlight">\(j\)</span> runs from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(m\)</span>, <span class="math notranslate nohighlight">\(s\)</span> runs
from <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(k\)</span> and as the vectors have length <span class="math notranslate nohighlight">\(\ell\)</span>. With <span class="math notranslate nohighlight">\(\ell=\tfrac{d}{m}\)</span> the running time reduces to <span class="math notranslate nohighlight">\(O(kd)\)</span>.
Then, using the look-up table, we compute for all <span class="math notranslate nohighlight">\(i\)</span> the scalar product <span class="math notranslate nohighlight">\(q^\intercal\hat x^{(i)}\)</span>, with a running time of
<span class="math notranslate nohighlight">\(O(nm)\)</span>. In total we obtain a running time of <span class="math notranslate nohighlight">\(O(kd+nm)\)</span>. As <span class="math notranslate nohighlight">\(n\)</span> is typically the by far largest quantity among
<span class="math notranslate nohighlight">\(d,k,n,m\)</span> the running time is dominated by <span class="math notranslate nohighlight">\(O(nm)\)</span>, and as usually <span class="math notranslate nohighlight">\(m \ll d\)</span>, we achieve a substantial reduction
in comparison to the running time <span class="math notranslate nohighlight">\(O(nd)\)</span> of the naive algorithm.</p>
<p>How should the representatives <span class="math notranslate nohighlight">\(c_{ji},\ldots,c_{jk}\in\mathbb R^\ell\)</span> be chosen? Well, <span class="math notranslate nohighlight">\(q^\intercal\hat x^{(i)}\)</span>
should be a good approximation of <span class="math notranslate nohighlight">\(q^\intercal x^{(i)}\)</span>, which is the case if <span class="math notranslate nohighlight">\(q^\intercal_j\hat x^{(i)}_j\)</span> is a
good approximation of <span class="math notranslate nohighlight">\(q^\intercal_jx^{(i)}_j\)</span> for every <span class="math notranslate nohighlight">\(j\in\{1,\ldots, m\}\)</span>. So, let’s fix <span class="math notranslate nohighlight">\(j\)</span> and
let us assume that the queries <span class="math notranslate nohighlight">\(q\)</span> are drawn from some distribution <span class="math notranslate nohighlight">\(\mathcal D\)</span>.
Then, arguably, we should choose <span class="math notranslate nohighlight">\(c_{j1},\ldots,c_{jk}\)</span> such that</p>
<div class="math notranslate nohighlight" id="equation-vqobj">
<span class="eqno">(1)<a class="headerlink" href="#equation-vqobj" title="Link to this equation">¶</a></span>\[\mathbb E_{q\sim\mathcal D}\left[\sum_{i=1}^n(q^\intercal_jx^{(i)}_j-q^\intercal_j\hat x^{(i)}_j)^2\right]\]</div>
<p>is minimised. Let us rewrite that.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbb E_{q\sim\mathcal D}\left[\sum_{i=1}^n\left(q^\intercal_jx^{(i)}_j-q^\intercal_j\hat x^{(i)}_j\right)^2\right]
&amp;= \sum_{i=1}^n\mathbb E_{q\sim\mathcal D}\left[\left(q^\intercal_j\left(x^{(i)}_j-\hat x^{(i)}_j\right)\right)^2\right]\\
&amp;=\sum_{i=1}^n\mathbb E_{q\sim\mathcal D}\left[\left( \cos\theta_{ij} ||q_j||\cdot ||x^{(i)}_j-\hat x^{(i)}_j|| \right)^2\right]\\
&amp;=\sum_{i=1}^n||x^{(i)}_j-\hat x^{(i)}_j||^2\cdot\mathbb E_{q\sim\mathcal D}\left[\left( \cos\theta_{ij} ||q_j||\right)^2\right],\end{split}\]</div>
<p>where we write <span class="math notranslate nohighlight">\(\theta_{ij}\)</span> for the angle between <span class="math notranslate nohighlight">\(q_j\)</span> and <span class="math notranslate nohighlight">\(x^{(i)}_j-\hat x^{(i)}_j\)</span>.</p>
<p>We’ve reached a point where we are stuck without further assumption on the distribution <span class="math notranslate nohighlight">\(\mathcal D\)</span>.
We do not want to impose strong conditions on it as it is quite outside our control.
However, not too far of a stretch seems to assume that <span class="math notranslate nohighlight">\(\mathcal D\)</span> is <em>isotropic</em>, ie, does not
depend on the direction. Under that assumption, we obtain:</p>
<div class="math notranslate nohighlight">
\[\mathbb E_{q\sim\mathcal D}\left[\sum_{i=1}^n\left(q^\intercal_jx^{(i)}_j-q^\intercal_j\hat x^{(i)}_j\right)^2\right]
=C\sum_{i=1}^n||x^{(i)}_j-\hat x^{(i)}_j||^2,\]</div>
<p>for some constant <span class="math notranslate nohighlight">\(C&gt;0\)</span> that only depends on <span class="math notranslate nohighlight">\(\mathcal D\)</span> but not on <span class="math notranslate nohighlight">\(\hat x^{(i)}_j\)</span>.</p>
<p>Recall that each <span class="math notranslate nohighlight">\(\hat x^{(i)}_j\)</span> is one of <span class="math notranslate nohighlight">\(c_{j1},\ldots,c_{jk}\)</span>. Thus</p>
<div class="math notranslate nohighlight">
\[\text{argmin}_{c_{j1},\ldots,c_{jk}} \mathbb E_{q\sim\mathcal D}\left[\sum_{i=1}^n\left(q^\intercal_jx^{(i)}_j-q^\intercal_j\hat x^{(i)}_j\right)^2\right]
= \text{argmin}_{c_{j1},\ldots,c_{jk}} \sum_{i=1}^n\min_{s}||x^{(i)}_j-c_{js}||^2,\]</div>
<p>which is nothing else than the <span class="math notranslate nohighlight">\(k\)</span>-means objective!</p>
<p>What does that mean? We split each database vector <span class="math notranslate nohighlight">\(x^{(i)}\)</span> into chunks of size <span class="math notranslate nohighlight">\(\tfrac{d}{m}\)</span>, and then, for each <span class="math notranslate nohighlight">\(j=1,\ldots, m\)</span>,
solve for the data <span class="math notranslate nohighlight">\(x^{(1)}_j,\ldots, x^{(n)}_j\)</span> a <span class="math notranslate nohighlight">\(k\)</span>-means clustering problem, resulting
in the centres <span class="math notranslate nohighlight">\(c_{j1},\ldots,c_{jk}\)</span>; finally we replace each <span class="math notranslate nohighlight">\(x^{(i)}_j\)</span> with the nearest cluster centre <span class="math notranslate nohighlight">\(c_{js}\)</span>.</p>
<p>Replacing vectors in a dataset by simpler vectors is  called <em>vector quantisation</em>, and also used as a compression tool,
for example, in video or audio codecs.</p>
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>The approach outlined here can be improved upon. Indeed, I’ve cheated with the objective <a class="reference internal" href="#equation-vqobj">(1)</a>: The objective
incorporates <em>all</em> scalar products <span class="math notranslate nohighlight">\(q^\intercal\hat x^{(i)}\)</span>. In the applications, however, we just want to find
the datapoint with largest scalar product with the query, or rather, the top-10 datapoints with largest scalar product.
Thus, it does not matter if <span class="math notranslate nohighlight">\(q^\intercal\hat x^{(i)}\)</span> deviates from <span class="math notranslate nohighlight">\(q^\intercal x^{(i)}\)</span> as long as both scalar products
are not too large. This insight can be used to devise a more complicated loss function that results in
better performance; see Guo et al. (2020). <a class="footnote-reference brackets" href="#fguo" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<p class="rubric">Footnotes</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="fquant" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><em>Quantization based Fast Inner Product Search</em>, R. Guo, S. Kumar, K. Choromanski and D. Simcha (2015), <a class="reference external" href="https://arxiv.org/abs/1509.01469">arXiv:1509.01469</a></p>
</aside>
<aside class="footnote brackets" id="fguo" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p><em>Accelerating Large-Scale Inference with Anisotropic Vector Quantization</em>, R. Guo, P. Sun, E. Lindgren, Q. Geng, D. Simcha, F. Chern and S. Kumar (2020), <a class="reference external" href="https://arxiv.org/pdf/1908.10396">arXiv:1908.10396</a></p>
</aside>
</aside>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">firsttest</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Maximum inner product search</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#vector-quantisation">Vector quantisation</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">firsttest documentation</a></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, me.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.1.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/contents/mips.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>